{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DzZH4_2Iw7e"
      },
      "source": [
        "# MNIST com Convolução"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfeP9IypHpv7"
      },
      "source": [
        "## Configurando a rede neural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IQ50eMhyOsbm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta parte estamaos preparando os dados após importar o dataset **mnist**. A ordem do preprocessamento:\n",
        "* Divisão dos dados em Teste e Treinamento\n",
        "* Escalona as imagens entre 0 e 1\n",
        "  * Os valores dos pixels estão representados em um range de 0 a 255, que é associado entre Preto (0) e Branco (255). Por isso devemos transformamos para float e dpois dividir por 255\n",
        "* Garantir que cada imagem possui a resolução correta (28x28 pixels)\n",
        "* Conversão de vetores para matrizes binarias"
      ],
      "metadata": {
        "id": "iarc2RUbbXZf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9ZrF1yPROUk",
        "outputId": "b9140a33-c8df-4776-f530-dab1becadab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "x_test shape: (10000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui estamos constuindo nosso modelo e definindo nossas camadas, além de suas configurações.\n",
        "Estamos usando 2 camadas de convolução, cada uma com um filtro de 32 e 64, respectivamente, representando a dimensão do output, além de ambas com um tamanho da janela de convolução (kernel_size) de 3x3.\n",
        "Cada uma dessas camadas é seguida por uma camada de pooling, que reduz o tamanho espacial da representação"
      ],
      "metadata": {
        "id": "m_kFeEUcjk2b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3Q30l-0SURN"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nHPeg20SWhr",
        "outputId": "6fb02489-ed3a-437b-f0cf-241b9d87fc06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                16010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34826 (136.04 KB)\n",
            "Trainable params: 34826 (136.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para o treinamento usamos um **batch size** de 128 e 3 **epochs**, como pedido na atividade"
      ],
      "metadata": {
        "id": "kRMmp_27l29V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj7qlIbRCKxV"
      },
      "source": [
        "## Treinando\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BojyG0W1Os0f",
        "outputId": "92a3c702-ed1a-4bb7-cb02-7f1f06ef3f1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "422/422 [==============================] - 13s 6ms/step - loss: 0.3751 - accuracy: 0.8877 - val_loss: 0.0890 - val_accuracy: 0.9768\n",
            "Epoch 2/3\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1154 - accuracy: 0.9653 - val_loss: 0.0595 - val_accuracy: 0.9838\n",
            "Epoch 3/3\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0862 - accuracy: 0.9731 - val_loss: 0.0450 - val_accuracy: 0.9875\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7804c811a9b0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "batch_size = 128\n",
        "epochs = 3\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDnGA55DOtzM"
      },
      "source": [
        "## Verificando o resultado"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo verificamos o resultado e garantimos que tivemos uma acuracia superior a pedida na atividade."
      ],
      "metadata": {
        "id": "dMeE84CwmMDh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrtF1sYZOvkG",
        "outputId": "a7ac9eee-8221-4641-efaa-e450f8353088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.0464\n",
            "Test accuracy: 0.9853\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test loss: {score[0]:.4f}\")\n",
        "print(f\"Test accuracy: {score[1]:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}